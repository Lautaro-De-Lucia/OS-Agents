{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you approach reconciling the ethical implications of artificial intelligence in decision-making processes across different cultural perspectives, while also considering the potential for biased outcomes?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes across different cultural perspectives involves a multifaceted approach that acknowledges cultural diversity, addresses biases, and promotes fairness and accountability. Here are some key steps to consider:\n",
       "\n",
       "### 1. **Understand Diverse Cultural Contexts**\n",
       "   - **Research Cultural Norms**: Engage in in-depth research to understand the values, beliefs, and social norms of different cultures. This includes recognizing how these factors influence perceptions of fairness, justice, and decision-making.\n",
       "   - **Stakeholder Engagement**: Involve representatives from diverse cultural backgrounds in conversations about AI. Collaborate with ethicists, community leaders, and affected individuals to ensure varied viewpoints are incorporated.\n",
       "\n",
       "### 2. **Identify and Mitigate Biases**\n",
       "   - **Bias Detection**: Implement rigorous testing for biases in AI systems. This includes examining training data for representational gaps and employing techniques to assess outcomes across different demographic groups.\n",
       "   - **Regular Audits**: Conduct regular audits of AI systems to monitor and evaluate their impact on various cultural groups, making necessary adjustments as findings dictate.\n",
       "\n",
       "### 3. **Framework Development**\n",
       "   - **Create Ethical Guidelines**: Develop a set of ethical guidelines that incorporate cultural perspectives and address potential biases. These guidelines should be adaptable to different contexts while maintaining core principles of fairness, transparency, and accountability.\n",
       "   - **Promote Multidisciplinary Collaboration**: Involve ethicists, sociologists, technologists, and cultural anthropologists in the AI development process to foster a holistic approach to decision-making.\n",
       "\n",
       "### 4. **Transparency and Accountability**\n",
       "   - **Clear Communication**: Ensure that the processes and algorithms used in AI decision-making are transparent and understandable to all stakeholders. This helps build trust and allows for informed feedback regarding potential biases.\n",
       "   - **Accountability Mechanisms**: Establish clear mechanisms for accountability in AI systems, including processes for individuals to appeal decisions made by AI and hold institutions accountable for biased outcomes.\n",
       "\n",
       "### 5. **Educate and Train**\n",
       "   - **Awareness Programs**: Develop educational programs that raise awareness about the ethical implications of AI and the importance of cultural sensitivity in technology.\n",
       "   - **Training for Developers**: Provide training for AI developers on cultural competence and ethical decision-making, emphasizing the importance of considering diverse cultural perspectives in their work.\n",
       "\n",
       "### 6. **Cultural Adaptation of AI Systems**\n",
       "   - **Customization**: Design AI systems that can be adapted to reflect the cultural contexts in which they are being deployed. This may involve localizing algorithms and interfaces to align with cultural preferences and ethical standards.\n",
       "   - **User-Centric Design**: Focus on user-centric design principles that incorporate feedback from local communities to create AI systems that resonate with cultural values and nuances.\n",
       "\n",
       "### 7. **International Collaboration**\n",
       "   - **Global Networks**: Build international collaborations to share best practices, research findings, and frameworks related to AI ethics across cultures. This can create a stronger foundation for understanding and addressing global challenges related to AI.\n",
       "   - **Policy Recommendations**: Advocate for the development of international standards and policies that promote ethical AI practices while respecting cultural differences.\n",
       "\n",
       "### Conclusion\n",
       "In addressing the ethical implications of AI decision-making across cultural perspectives, it is essential to cultivate an inclusive, transparent, and accountable environment. Balancing ethical considerations with the challenges of bias requires continuous dialogue, adaptation, and a commitment to understanding the complex interplay of technology and culture. By taking proactive steps in these areas, we can work toward AI systems that are not only ethical but also culturally sensitive and equitable."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini (Gemine 2.0 Flash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering the socio-political implications of widespread, advanced AI deployment, at what point does the potential for systemic bias mitigation outweigh the risks associated with the consolidation of power necessary to enforce standardized ethical frameworks across diverse AI models, and how would you quantify that point?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This is a complex question with no easy answer. It essentially asks: at what point does the potential benefit of reducing bias in AI, which requires standardization and thus potentially central control, outweigh the risk of that centralized control being used for undesirable purposes (e.g., oppression, suppression of dissent)?  It's a balancing act between preventing widespread AI-driven discrimination and risking authoritarianism in the name of fairness.\n",
       "\n",
       "Here's a breakdown of the factors to consider and how we might approach quantifying the \"tipping point\":\n",
       "\n",
       "**Arguments for Standardized Ethical Frameworks & Centralized Enforcement:**\n",
       "\n",
       "* **Bias Mitigation:** AI models are trained on data, and if that data reflects societal biases (e.g., sexism, racism), the AI will perpetuate and amplify them. Standardized ethical frameworks can define prohibited biases and create metrics to measure and mitigate them across all AI models.  Central enforcement ensures these frameworks are followed.\n",
       "* **Accountability:**  When AI systems make mistakes, it's often difficult to assign responsibility. Standardized frameworks can help clarify accountability by setting clear expectations and establishing mechanisms for redress.  Central enforcement can hold developers and deployers accountable.\n",
       "* **Interoperability & Safety:**  Standardized ethical guidelines can ensure that AI systems interact safely and predictably with each other and with humans.  This is crucial for fields like autonomous vehicles and healthcare.\n",
       "* **Public Trust:** Widespread deployment of biased or unsafe AI can erode public trust, hindering the adoption of beneficial AI applications. Standardized ethical frameworks can help build trust by demonstrating a commitment to fairness and safety.\n",
       "\n",
       "**Arguments Against Standardized Ethical Frameworks & Centralized Enforcement:**\n",
       "\n",
       "* **Consolidation of Power:**  Enforcing standardized ethical frameworks requires a powerful entity (government, international body, or corporation) with the ability to monitor and regulate AI development and deployment. This concentration of power could be abused to suppress dissent, manipulate public opinion, or favor certain groups over others.\n",
       "* **Stifling Innovation:**  Overly rigid frameworks can stifle innovation by limiting the freedom of researchers and developers to explore new ideas. A centrally enforced \"one-size-fits-all\" approach may not be suitable for all AI applications.\n",
       "* **Lack of Adaptability:**  Societal values and ethical considerations evolve over time. Centralized frameworks may be slow to adapt to these changes, leading to outdated or ineffective regulations.\n",
       "* **Cultural Relativism:**  What is considered ethical in one culture may not be ethical in another. Imposing a single, globally enforced framework could lead to cultural imperialism and resentment.\n",
       "* **Unintended Consequences:**  Even well-intentioned frameworks can have unintended consequences. For example, overly strict regulations on facial recognition technology could hinder law enforcement and security efforts.\n",
       "\n",
       "**Quantifying the \"Tipping Point\" - A Difficult Task:**\n",
       "\n",
       "Quantifying this tipping point is extremely challenging and likely impossible to do with perfect accuracy. However, we can use a framework that considers various factors and assigns them relative weights:\n",
       "\n",
       "**1.  Define Key Metrics:**\n",
       "\n",
       "*   **Bias Reduction (BR):** Measured as a percentage reduction in bias across various AI applications (e.g., loan applications, hiring processes, criminal justice). This would require developing standardized metrics for identifying and measuring bias in AI.\n",
       "*   **Innovation Loss (IL):** Measured as a percentage decrease in AI research and development funding, patent applications, and the emergence of new AI startups.  Could also be measured by a decline in fundamental breakthroughs.\n",
       "*   **Power Consolidation (PC):** Measured using indicators of authoritarianism, such as freedom of speech, freedom of the press, political rights, and civil liberties (e.g., using indices from Freedom House or Reporters Without Borders).  This would need to be AI-specific â€“ focusing on control over AI development, deployment, and access.\n",
       "*   **Unintended Consequences (UC):** A composite measure based on observed negative impacts, such as job displacement, increased surveillance, and reduced privacy. This would require ongoing monitoring and evaluation of AI deployments.\n",
       "*   **Public Trust (PT):** Measured through surveys and public opinion polls regarding trust in AI systems and the entities that regulate them.\n",
       "\n",
       "**2.  Assign Weights (Subjective but Crucial):**\n",
       "\n",
       "This is where societal values come into play.  Different societies may prioritize different values. For example:\n",
       "\n",
       "*   A society that highly values individual liberty might assign a high weight to Innovation Loss (IL) and Power Consolidation (PC).\n",
       "*   A society that prioritizes social justice might assign a high weight to Bias Reduction (BR).\n",
       "\n",
       "Example Weights (these are hypothetical and should be determined through democratic processes):\n",
       "\n",
       "*   BR = 40%\n",
       "*   IL = 20%\n",
       "*   PC = 25%\n",
       "*   UC = 10%\n",
       "*   PT = 5%\n",
       "\n",
       "**3.  Develop a Formula:**\n",
       "\n",
       "A simple formula could be:\n",
       "\n",
       "`Value = (W_BR * BR) - (W_IL * IL) - (W_PC * PC) - (W_UC * UC) + (W_PT * PT)`\n",
       "\n",
       "Where:\n",
       "\n",
       "*   `W_x` is the weight assigned to metric `x`.\n",
       "*   `BR`, `IL`, `PC`, `UC`, and `PT` are the values of the respective metrics (expressed as percentages).\n",
       "\n",
       "**4.  Monitor and Adjust:**\n",
       "\n",
       "*   Continuously monitor the key metrics and adjust the weights as societal values evolve and new information becomes available.\n",
       "*   Implement pilot programs and conduct rigorous evaluations to assess the impact of different regulatory approaches.\n",
       "*   Involve diverse stakeholders in the decision-making process, including AI researchers, developers, ethicists, policymakers, and the public.\n",
       "\n",
       "**The \"Tipping Point\":**\n",
       "\n",
       "The tipping point would be when the \"Value\" calculated by the formula starts to decline significantly, indicating that the negative consequences of centralized enforcement are outweighing the benefits of bias reduction.\n",
       "\n",
       "**Challenges & Considerations:**\n",
       "\n",
       "*   **Measurement Difficulty:** Accurately measuring bias, innovation loss, power consolidation, and unintended consequences is extremely difficult and requires sophisticated methodologies.\n",
       "*   **Subjectivity:**  The assignment of weights is inherently subjective and requires careful consideration of societal values.\n",
       "*   **Dynamic System:** The AI landscape is constantly evolving, so the framework must be adaptable and updated regularly.\n",
       "*   **Global Coordination:**  AI is a global technology, and effective regulation requires international cooperation and coordination.\n",
       "*   **Defining \"Ethical\":** Whose definition of \"ethical\" is used?  A framework needs to be inclusive and account for diverse perspectives.\n",
       "\n",
       "**Conclusion:**\n",
       "\n",
       "Finding the right balance between bias mitigation and power consolidation is a critical challenge.  While a precise, universally accepted quantitative solution is unlikely, a framework based on carefully defined metrics, weighted according to societal values, and continuously monitored and adjusted, can provide a valuable tool for navigating this complex issue.  The key is to be transparent, inclusive, and adaptable in our approach.  Furthermore, decentralization techniques such as federated learning and differential privacy should be explored to minimize the need for centralized data collection and control.  Ultimately, the goal is to create a future where AI is used for the benefit of all, without sacrificing fundamental values such as freedom, autonomy, and fairness.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]\n",
    "\n",
    "openai = OpenAI(api_key=GEMINI_API_KEY, base_url=GEMINI_BASE_URL)\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gemini-2.0-flash\", messages=messages)\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n",
    "\n",
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gemini-2.0-flash\", messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(\"gemini-2.0-flash\")\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huggingface (Mixtral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.\n",
      "\n",
      "What is the difference between \"legal personality\" and \"natural personality\" and why does it matter both in general and for international investment law?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.\n",
       "\n",
       "What is the difference between \"legal personality\" and \"natural personality\" and why does it matter both in general and for international investment law? To what extent is the concept of a \"legal personality\" compatible with some fundamental ideas about the relationship between state power and individual rights or does the distinction instead represent another way in which states have the power to reallocate resources without sufficient checks or balances?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "HF_TOKEN = os.getenv('HUGGINGFACE_TOKEN')\n",
    "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "\n",
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "\n",
    "response = requests.post(API_URL, headers=headers, json={\"inputs\": request})\n",
    "question = response.json()[0][\"generated_text\"]\n",
    "print(question)\n",
    "\n",
    "competitors = []\n",
    "answers = []\n",
    "\n",
    "response = requests.post(API_URL, headers=headers, json={\"inputs\": question})\n",
    "answer = response.json()[0][\"generated_text\"]\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(\"Mixtral-8x7B\")\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama (TinyLlama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Can you explain how AI systems and artificial intelligence technologies work, using simple terms and examples?\n",
      "\n",
      "Adapted from this interview with Dr. Jyotsna Sareen on AI and Artificial Intelligence in India.\n",
      "\n",
      "Interviewer: Explain the concept of \"intelligent machines\" to a group of LLB students.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Certainly! I'd be happy to explain the concept of \"intelligent machines\" or AI systems using simple terms and examples.\n",
       "\n",
       "1. What is an \"intelligent machine\"?\n",
       "\n",
       "An \"intelligent machine\" is a device that can perform tasks without being explicitly programmed. Examples of intelligent machines include robotic arms, self-driving cars, chatbots, and virtual assistants on smartphones and computers. AI systems are not made up of individual components but rather work together to accomplish their goals based on complex algorithms and programming.\n",
       "\n",
       "2. How do AI systems learn and make decisions?\n",
       "\n",
       "AI systems use a process called reinforcement learning to make decisions and improve their performance over time. This involves training the system on past data or examples, such as user interactions or machine-learned patterns, using a reward system. The system can then use this experience to solve new problems or adapt its behavior based on the feedback it receives.\n",
       "\n",
       "For example, an AI chatbot might learn from previous conversations with users about what they like and dislike to make more personalized recommendations for future interactions. It might also adjust its language, tone, and style based on feedback from other chatbots or human support staff, improving its overall performance over time.\n",
       "\n",
       "3. What are some advantages and limitations of AI systems?\n",
       "\n",
       "Advantages:\n",
       "- High levels of accuracy in tasks such as translation, speech recognition, and image recognition.\n",
       "- Improved decision-making capabilities for complex problems like healthcare, finance, and transportation.\n",
       "- Increased efficiency and productivity in fields like manufacturing, logistics, and customer service.\n",
       "\n",
       "Limitations:\n",
       "- Dependence on data and algorithms to function correctly.\n",
       "- Lack of human interaction or empathy, which can be problematic in some scenarios.\n",
       "- Scalability issues as more data is added or tasks become more complex.\n",
       "\n",
       "In conclusion, AI systems are becoming increasingly advanced and sophisticated, with the potential to revolutionize various industries and fields. While there are both advantages and limitations, it's clear that AI systems will continue to improve over time thanks to advancements in technology and machine learning algorithms."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "model_name = \"tinyllama\"\n",
    "\n",
    "def get_ollama_response(prompt):\n",
    "    response = requests.post(OLLAMA_URL, json={\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False  # you can also disable streaming this way\n",
    "    })\n",
    "    return response.json()[\"message\"][\"content\"]\n",
    "\n",
    "# STEP 1: Get question\n",
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "question = get_ollama_response(request)\n",
    "print(question)\n",
    "\n",
    "# STEP 2: Get answer to question\n",
    "answer = get_ollama_response(question)\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors = [model_name]\n",
    "answers = [answer]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other API Providers we are not Paying For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            and common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
